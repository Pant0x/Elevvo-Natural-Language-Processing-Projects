{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nfrom datasets import Dataset\nimport evaluate\nfrom bs4 import BeautifulSoup\nimport nltk\nimport re\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)\n\nnltk.download(\"punkt\")","metadata":{"_uuid":"bc38e071-7274-4c2f-bc32-fb49180fa523","_cell_guid":"bafb29e4-487f-4851-8140-55f9d607d84e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-12T21:52:39.820405Z","iopub.execute_input":"2025-11-12T21:52:39.820743Z","iopub.status.idle":"2025-11-12T21:52:40.186478Z","shell.execute_reply.started":"2025-11-12T21:52:39.820719Z","shell.execute_reply":"2025-11-12T21:52:40.185700Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\").dropna(subset=[\"article\", \"highlights\"])\nval_df   = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\").dropna(subset=[\"article\", \"highlights\"])\ntest_df  = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\").dropna(subset=[\"article\", \"highlights\"])\n\n# Optional: quick preview\nfor i in range(3):\n    print(f\"\\n--- Article {i} ---\\nArticle length: {len(train_df['article'][i])}\")\n    print(f\"Highlights length: {len(train_df['highlights'][i])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T21:53:16.067461Z","iopub.execute_input":"2025-11-12T21:53:16.067849Z","iopub.status.idle":"2025-11-12T21:53:31.305222Z","shell.execute_reply.started":"2025-11-12T21:53:16.067828Z","shell.execute_reply":"2025-11-12T21:53:31.304506Z"}},"outputs":[{"name":"stdout","text":"\n--- Article 0 ---\nArticle length: 1211\nHighlights length: 220\n\n--- Article 1 ---\nArticle length: 2544\nHighlights length: 223\n\n--- Article 2 ---\nArticle length: 4743\nHighlights length: 390\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def clean_text(text):\n    text = BeautifulSoup(text, \"html.parser\").get_text()\n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\nfor df in [train_df, val_df, test_df]:\n    df[\"article\"] = df[\"article\"].map(clean_text)\n    df[\"highlights\"] = df[\"highlights\"].map(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T21:54:07.165587Z","iopub.execute_input":"2025-11-12T21:54:07.166240Z","iopub.status.idle":"2025-11-12T21:56:05.862618Z","shell.execute_reply.started":"2025-11-12T21:54:07.166216Z","shell.execute_reply":"2025-11-12T21:56:05.861985Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from transformers import pipeline\nfrom evaluate import load\nimport torch\n\n# Summarization pipeline (no device argument)\nsummarizer = pipeline(\n    \"summarization\",\n    model=model,\n    tokenizer=tokenizer\n)\n\n# Load ROUGE metric\nrouge_metric = load(\"rouge\")\n\ndef compute_rouge(dataset, n_samples=100, max_input_length=512):\n    preds, refs = [], []\n    \n    for i in range(min(n_samples, len(dataset))):\n        text = dataset[i][\"article\"]\n        ref = dataset[i][\"highlights\"]\n        \n        # Truncate to model max length\n        inputs = tokenizer(\n            text,\n            max_length=max_input_length,\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n        # Generate summary safely on CPU\n        summary_ids = model.generate(\n            **inputs,\n            max_length=150,\n            min_length=40,\n            length_penalty=2.0,\n            num_beams=4,\n            early_stopping=True\n        )\n        summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n        \n        if summary_text.strip():  # only keep non-empty\n            preds.append(summary_text.strip())\n            refs.append(ref.strip())\n        else:\n            print(f\"Skipping article {i} due to empty summary\")\n    \n    if not preds:\n        print(\"No valid summaries to compute ROUGE.\")\n        return {}\n    \n    # Compute ROUGE\n    results = rouge_metric.compute(predictions=preds, references=refs)\n    \n    # Convert to % for readability\n    results_percent = {k: v * 100 for k, v in results.items()}\n    return results_percent\n\n# Run evaluation\nrouge_scores = compute_rouge(test_data, n_samples=10)  # small test set\nprint(\"ROUGE Scores:\", rouge_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:03:38.800287Z","iopub.execute_input":"2025-11-12T22:03:38.800836Z","iopub.status.idle":"2025-11-12T22:04:07.082391Z","shell.execute_reply.started":"2025-11-12T22:03:38.800810Z","shell.execute_reply":"2025-11-12T22:04:07.081633Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"ROUGE Scores: {'rouge1': 39.03897245511171, 'rouge2': 16.677957020145957, 'rougeL': 26.647338042074885, 'rougeLsum': 32.938090097749914}\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"MAX_INPUT_TOKENS = 1024\nMAX_SUMMARY_TOKENS = 150\nMIN_SUMMARY_TOKENS = 40\n\ndef safe_summarize(text):\n    \"\"\"Generate summary safely on CPU, truncates input to model limit\"\"\"\n    try:\n        inputs = tokenizer(\n            text,\n            max_length=MAX_INPUT_TOKENS,\n            truncation=True,\n            return_tensors=\"pt\"\n        )  # no .to(device), CPU only\n\n        summary_ids = model.generate(\n            **inputs,\n            max_length=MAX_SUMMARY_TOKENS,\n            min_length=MIN_SUMMARY_TOKENS,\n            length_penalty=2.0,\n            num_beams=4,\n            early_stopping=True\n        )\n        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n        return summary\n    except Exception as e:\n        print(f\"Skipping article due to error: {e}\")\n        return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:06:19.906951Z","iopub.execute_input":"2025-11-12T22:06:19.907236Z","iopub.status.idle":"2025-11-12T22:06:19.912516Z","shell.execute_reply.started":"2025-11-12T22:06:19.907215Z","shell.execute_reply":"2025-11-12T22:06:19.911593Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"#BONUS\n\nrouge = evaluate.load(\"rouge\")\n\ndef compute_rouge(df, n_samples=100):\n    preds, refs = [], []\n    for i in range(min(n_samples, len(df))):\n        article = df.iloc[i][\"article\"]\n        reference = df.iloc[i][\"highlights\"]\n        summary = safe_summarize(article)\n        if summary.strip() == \"\":\n            continue  # skip empty summaries\n        preds.append(summary)\n        refs.append(reference)\n\n    if len(preds) == 0:\n        print(\"No valid summaries to compute ROUGE.\")\n        return {}\n\n    results = rouge.compute(predictions=preds, references=refs)\n    return {k: v * 100 for k, v in results.items()}\n\n# Run evaluation on test set\nrouge_scores = compute_rouge(test_df, n_samples=100)\nprint(\"ROUGE Scores:\", rouge_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:06:22.097189Z","iopub.execute_input":"2025-11-12T22:06:22.097813Z","iopub.status.idle":"2025-11-12T22:12:17.689869Z","shell.execute_reply.started":"2025-11-12T22:06:22.097788Z","shell.execute_reply":"2025-11-12T22:12:17.689109Z"}},"outputs":[{"name":"stdout","text":"ROUGE Scores: {'rouge1': 35.27787474858648, 'rouge2': 15.045180398223785, 'rougeL': 24.398642095880675, 'rougeLsum': 24.51258623335181}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"for i in range(3):\n    article = test_df.iloc[i][\"article\"]\n    summary = safe_summarize(article)\n    print(f\"\\n--- ARTICLE {i} ---\\n{article[:400]}...\\n\")\n    print(f\"--- SUMMARY ---\\n{summary}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:12:23.573726Z","iopub.execute_input":"2025-11-12T22:12:23.574262Z","iopub.status.idle":"2025-11-12T22:12:31.516744Z","shell.execute_reply.started":"2025-11-12T22:12:23.574237Z","shell.execute_reply":"2025-11-12T22:12:31.516007Z"}},"outputs":[{"name":"stdout","text":"\n--- ARTICLE 0 ---\nEver noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on ...\n\n--- SUMMARY ---\n, while some airlines offer as little as 28 inches of space. some experts are questioning if shrinking space on planes is putting our health and safety in danger. experts say that shrinking space on planes is not only uncomfortable - it's putting our health and safety in danger.\n\n\n--- ARTICLE 1 ---\nA drunk teenage boy had to be rescued by security after jumping into a lions' enclosure at a zoo in western India. Rahul Kumar, 17, clambered over the enclosure fence at the Kamla Nehru Zoological Park in Ahmedabad, and began running towards the animals, shouting he would 'kill them'. Mr Kumar explained afterwards that he was drunk and 'thought I'd stand a good chance' against the predators. Next ...\n\n--- SUMMARY ---\nRahul Kumar, 17, climbed into a lions' enclosure at a zoo in western india. he ran towards the animals shouting: 'Today I kill a lion or a lion kills me!' luckily, he fell into a moat as he ran towards the lions. he could be rescued by zoo security staff before reaching the animals.\n\n\n--- ARTICLE 2 ---\nDougie Freedman is on the verge of agreeing a new two-year deal to remain at Nottingham Forest. Freedman has stabilised Forest since he replaced cult hero Stuart Pearce and the club's owners are pleased with the job he has done at the City Ground. Dougie Freedman is set to sign a new deal at Nottingham Forest . Freedman has impressed at the City Ground since replacing Stuart Pearce in February . T...\n\n--- SUMMARY ---\nDougie Freedman is set to sign a new two-year deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. the club's owners are pleased with the job he has done at the City Ground.\n\n","output_type":"stream"}],"execution_count":43}]}